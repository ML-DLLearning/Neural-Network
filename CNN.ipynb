{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5312f2e4",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network(CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73982402",
   "metadata": {},
   "source": [
    "可应用于图像分类，目标检测，图像分割，人脸识别与验证，图像生成与风格迁移，视频分析，图像超分辨率、去噪……在CV领域用处颇广"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29993cb2",
   "metadata": {},
   "source": [
    "torchvision 是 PyTorch 官方提供的CV工具库，包含了很多常用的数据集和数据预处理工具。  \n",
    "datasets.MNIST 是其中的数据集类之一，专门用于 MNIST 数据集，用于自动下载和加载经典的 MNIST 手写数字数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EPOCH = 1\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.00015\n",
    "DOWNLOAD_MNIST = False #是否下载数据集，若本地已经下载过则设为 False\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d46cf70",
   "metadata": {},
   "source": [
    "①root='./data', 数据集的下载和保存路径,MNIST 数据会下载/解压到 ./data 这个文件夹下  \n",
    "②train=True,选择加载的是训练集还是测试集。train=True：加载训练集（60000 张图片）;train=False：加载测试集（10000 张图片）  \n",
    "③transform=torchvision.transforms.ToTensor(),把每张图片由 PIL.Image 或 numpy.ndarray 格式转成 PyTorch 用的 tensor 格式，并且像素值缩放到 [0,1] 区间（浮点数）（将图片由RGB压缩为灰白二维）  \n",
    "④download=True 是否需要下载数据集。如果为 True，则自动下载数据集（当本地没有时）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ffbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(train_data.train_data.size())\n",
    "# 打印包含所有训练图片的张量各维度的大小   # 60000 张 28x28 的图片\n",
    "print(train_data.train_labels.size())\n",
    "# 打印训练图片对应的标签（比如每个图片是哪个数字，0~9）   # 60000 个数字标签\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "#imshow = image show，用于输出第0张图片\n",
    "#matplotlib 画图需要 numpy 格式，所以要把 PyTorch tensor 转成 numpy 数组\n",
    "plt.title(f'{train_data.train_labels[0].item()}') # .item() 把张量转成 Python int （不加也可以）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f3cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538d8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\deeplearning NN\\.venv\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:71: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "#把测试图片变成了 shape 为 [10000, 1, 28, 28]、像素值在 0~1 之间(归一化处理)的 float 格式\n",
    "test_x = torch.unsqueeze(test_data.data, dim=1).float() / 255.0\n",
    "#这行代码把测试集前 2000 个图片的标签提取出来\n",
    "test_y = test_data.test_labels[:1000]#[:2000]：只取前 2000 个标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab45c76",
   "metadata": {},
   "source": [
    "训练数据(traindata)  \n",
    "用于训练模型，即让模型“学习”数据中的规律  \n",
    "测试数据(testdata)  \n",
    "用于评估模型的泛化能力，即测试模型在未见过的数据上的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c77ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #第一层卷积层\n",
    "        self.conv1 = nn.Sequential(         #这一层图片的维度为（1，28，28）（长宽高）\n",
    "            nn.Conv2d(\n",
    "                in_channels=1, #输入的图片的高度/通道数，灰度图就是1，彩色图就是3(r、g、b)\n",
    "                out_channels=16, #卷积核的个数，即输出的通道数\n",
    "                #就是有k个filter/kernel/卷积核在同一位置提取图片的特征，就把这k个特征叠起来（层数变为k）作为下一层的输入\n",
    "                kernel_size=5, #卷积核的大小是5x5（单位：像素点）\n",
    "                stride=1, #卷积核每次移动的步长，单位是像素点\n",
    "                padding=2 #边缘处理：在图片的边缘补0，补2圈——>为了让输出的图片的长和宽保持不变\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)#新的卷积核尺寸为2x2   #这一步之后图片的长宽发生改变\n",
    "         )\n",
    "        self.conv2 = nn.Sequential(         #(16，14，14)\n",
    "            nn.Conv2d(16,32,5,1,2),         #(32，14，14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)                 #(32，7，7)\n",
    "        )\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)#将三维的数据展平为一维，方便进行分类\n",
    "        #10是out_features = 10，就是分类的类别数（比如MNIST手写数字识别有10个类别：0~9）\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)           #维度是(batch，32，7，7)\n",
    "        x = x.view(x.size(0), -1)   #（batch，32*7*7） -1的作用即是把后三个三维展平为一维\n",
    "        #view()用于重塑形状  #x.size(0)即取了x的shape的第一个特征量\n",
    "        output = self.out(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448ef44",
   "metadata": {},
   "source": [
    "每层卷积层包含以下的组件：  \n",
    "nn.Conv2d(...)：二维卷积层，对输入图片做卷积操作，自动提取局部特征（比如边缘、纹理等）  \n",
    "nn.ReLU()：AF，为卷积输出增加非线性，提升模型表达能力  \n",
    "nn.MaxPool2d(2)：二维最大池化层，池化窗口大小为2。对特征图做降采样，减少数据量、参数量，增强特征的空间不变性。效果：每2x2区域取最大值，缩小特征图尺寸（比如从28x28变成14x14）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98158ed",
   "metadata": {},
   "source": [
    "卷积：滑动遍历整张图片，变成若干张特征图（如16张）。   \n",
    "激活：将特征图做非线性变换。  \n",
    "池化：在卷积的基础上，筛选出重要信息。特征图尺寸减半，变成14×14，更精炼。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4d450",
   "metadata": {},
   "source": [
    "***每次卷积后的输出***（改变高度）：out_channels=16，意为16个卷积核同时处理了一块区域，叠加后得到了一个长和宽更小的，但是更厚（高）的patch作为输出  \n",
    "***边缘处理的计算***：如果stride = 1，那么pedding = (kernal_size - 1)/2,这是为了保证输出图片的*长和宽*和原来*保持不变*  \n",
    "***卷积出的特征图的拼接***：肯定会有重叠，中心位置对齐即可  \n",
    "***池化层***（改变长和宽）：用一个比卷积层更小的filter遍历卷积层输出的特征图，挑选这个filter区域中的最大值作为新的像素的值（这只是MaxPool2d的做法），把这个filter覆盖的区域合并为一个像素块并把那个最大值作为其像素值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bcfa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61590588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | train loss: 2.3250 | test accuracy: 0.04\n",
      "Epoch:  0 | train loss: 2.1443 | test accuracy: 0.32\n",
      "Epoch:  0 | train loss: 1.6064 | test accuracy: 0.73\n",
      "Epoch:  0 | train loss: 0.8898 | test accuracy: 0.81\n",
      "Epoch:  0 | train loss: 0.5688 | test accuracy: 0.82\n",
      "Epoch:  0 | train loss: 0.4071 | test accuracy: 0.84\n",
      "Epoch:  0 | train loss: 0.6170 | test accuracy: 0.87\n",
      "Epoch:  0 | train loss: 0.6023 | test accuracy: 0.87\n",
      "Epoch:  0 | train loss: 0.2572 | test accuracy: 0.88\n",
      "Epoch:  0 | train loss: 0.0931 | test accuracy: 0.89\n",
      "Epoch:  0 | train loss: 0.1975 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.2938 | test accuracy: 0.90\n",
      "Epoch:  0 | train loss: 0.3033 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.4409 | test accuracy: 0.91\n",
      "Epoch:  0 | train loss: 0.3750 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1639 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.3245 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.2831 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1144 | test accuracy: 0.92\n",
      "Epoch:  0 | train loss: 0.1944 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.2025 | test accuracy: 0.94\n",
      "Epoch:  0 | train loss: 0.2857 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.1096 | test accuracy: 0.93\n",
      "Epoch:  0 | train loss: 0.2246 | test accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#training & testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        output = cnn(x)               # cnn output\n",
    "        loss = loss_fn(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            test_output = cnn(test_x[:1000])            # 1000张测试图片\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()#torch.max(test_output, 1)[1]：取每行最大值的索引作为预测类别\n",
    "            accuracy = sum(pred_y == test_y) / float(test_y.size(0))\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item(), '| test accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa1d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9] prediction number\n",
      "[7 2 1 0 4 1 4 9 5 9] real number\n"
     ]
    }
   ],
   "source": [
    "test_output = cnn(test_x[:10])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(test_y[:10].numpy(), 'real number')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
