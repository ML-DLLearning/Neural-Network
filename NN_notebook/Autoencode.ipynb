{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ce77432",
   "metadata": {},
   "source": [
    "# Autoencode(unsupervised learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb180feb",
   "metadata": {},
   "source": [
    "编码器(encoder)——特征集——解码器(decoder)  \n",
    "学习目标：Autoencoder 的输出尽可能接近输入"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373c68e",
   "metadata": {},
   "source": [
    "应用：  \n",
    "数据降维：类似于主成分分析（PCA），可以将高维数据映射到低维空间，同时保留主要特征。  \n",
    "特征提取：提取输入数据的特征，用于后续的分类或聚类任务。  \n",
    "去噪（Denoising Autoencoder）：学习在噪声数据中提取干净的特征，重构出无噪声的输入。  \n",
    "生成模型（Variational Autoencoder, VAE）：用于生成新数据样本，例如图像生成。  \n",
    "异常检测：学习正常数据分布，通过重构误差检测异常数据  \n",
    "\n",
    "工作流程：  \n",
    "输入数据：把原始数据作为输入，例如图像、声音、文本等。  \n",
    "编码阶段：数据通过编码器被压缩成一个低维的潜在表示。  \n",
    "解码阶段：从潜在表示重构数据。  \n",
    "优化损失函数：损失函数衡量输入与输出之间的差异，并通过反向传播优化网络参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa6644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "EPOCH = 10\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.005\n",
    "DOWNLOAD_MNIST = False\n",
    "N_TEST_IMG = 5\n",
    "\n",
    "###已更新为现代写法\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist',\n",
    "    train=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    download=DOWNLOAD_MNIST\n",
    ")\n",
    "\n",
    "print(train_data.data.size())#data：用于访问图像数据\n",
    "print(train_data.targets.size())#targets：用于访问标签\n",
    "plt.imshow(train_data.data[2].numpy(), cmap='gray')\n",
    "plt.title(\"Sample Image\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5264900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12,3)\n",
    "            \n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Sigmoid()#将输出限制在0-1之间\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return encoded, decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730b86a",
   "metadata": {},
   "source": [
    "可以压缩的原因(Linear)：将高维数据通过矩阵乘法映射到一个低维空间，同时保留主要的特征信息  \n",
    "通过y=Wx+b —— x (batchsize,784) \\ W (128,784) \\ b (128) \\ y (batchsize,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "486b88ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=64, out_features=12, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=12, out_features=3, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=12, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=12, out_features=64, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=128, out_features=784, bias=True)\n",
      "    (7): Sigmoid()\n",
      "  )\n",
      ")\n",
      "torch.Size([32, 1, 28, 28])\n",
      "Epoch:  0 | train loss: 0.2322\n",
      "Epoch:  0 | train loss: 0.0701\n",
      "Epoch:  0 | train loss: 0.0620\n",
      "Epoch:  0 | train loss: 0.0596\n",
      "Epoch:  0 | train loss: 0.0533\n",
      "Epoch:  0 | train loss: 0.0491\n",
      "Epoch:  0 | train loss: 0.0454\n",
      "Epoch:  0 | train loss: 0.0454\n",
      "Epoch:  0 | train loss: 0.0465\n",
      "Epoch:  0 | train loss: 0.0426\n",
      "Epoch:  1 | train loss: 0.0399\n",
      "Epoch:  1 | train loss: 0.0396\n",
      "Epoch:  1 | train loss: 0.0405\n",
      "Epoch:  1 | train loss: 0.0429\n",
      "Epoch:  1 | train loss: 0.0364\n",
      "Epoch:  1 | train loss: 0.0382\n",
      "Epoch:  1 | train loss: 0.0391\n",
      "Epoch:  1 | train loss: 0.0415\n",
      "Epoch:  1 | train loss: 0.0344\n",
      "Epoch:  1 | train loss: 0.0383\n",
      "Epoch:  2 | train loss: 0.0392\n",
      "Epoch:  2 | train loss: 0.0381\n",
      "Epoch:  2 | train loss: 0.0386\n",
      "Epoch:  2 | train loss: 0.0361\n",
      "Epoch:  2 | train loss: 0.0382\n",
      "Epoch:  2 | train loss: 0.0382\n",
      "Epoch:  2 | train loss: 0.0374\n",
      "Epoch:  2 | train loss: 0.0388\n",
      "Epoch:  2 | train loss: 0.0333\n",
      "Epoch:  2 | train loss: 0.0332\n",
      "Epoch:  3 | train loss: 0.0357\n",
      "Epoch:  3 | train loss: 0.0378\n",
      "Epoch:  3 | train loss: 0.0341\n",
      "Epoch:  3 | train loss: 0.0339\n",
      "Epoch:  3 | train loss: 0.0386\n",
      "Epoch:  3 | train loss: 0.0390\n",
      "Epoch:  3 | train loss: 0.0383\n",
      "Epoch:  3 | train loss: 0.0345\n",
      "Epoch:  3 | train loss: 0.0383\n",
      "Epoch:  3 | train loss: 0.0378\n",
      "Epoch:  4 | train loss: 0.0380\n",
      "Epoch:  4 | train loss: 0.0343\n",
      "Epoch:  4 | train loss: 0.0365\n",
      "Epoch:  4 | train loss: 0.0382\n",
      "Epoch:  4 | train loss: 0.0358\n",
      "Epoch:  4 | train loss: 0.0333\n",
      "Epoch:  4 | train loss: 0.0373\n",
      "Epoch:  4 | train loss: 0.0369\n",
      "Epoch:  4 | train loss: 0.0365\n",
      "Epoch:  4 | train loss: 0.0374\n",
      "Epoch:  5 | train loss: 0.0341\n",
      "Epoch:  5 | train loss: 0.0379\n",
      "Epoch:  5 | train loss: 0.0352\n",
      "Epoch:  5 | train loss: 0.0385\n",
      "Epoch:  5 | train loss: 0.0325\n",
      "Epoch:  5 | train loss: 0.0361\n",
      "Epoch:  5 | train loss: 0.0403\n",
      "Epoch:  5 | train loss: 0.0344\n",
      "Epoch:  5 | train loss: 0.0355\n",
      "Epoch:  5 | train loss: 0.0341\n",
      "Epoch:  6 | train loss: 0.0364\n",
      "Epoch:  6 | train loss: 0.0343\n",
      "Epoch:  6 | train loss: 0.0375\n",
      "Epoch:  6 | train loss: 0.0346\n",
      "Epoch:  6 | train loss: 0.0351\n",
      "Epoch:  6 | train loss: 0.0313\n",
      "Epoch:  6 | train loss: 0.0307\n",
      "Epoch:  6 | train loss: 0.0369\n",
      "Epoch:  6 | train loss: 0.0356\n",
      "Epoch:  6 | train loss: 0.0311\n",
      "Epoch:  7 | train loss: 0.0374\n",
      "Epoch:  7 | train loss: 0.0377\n",
      "Epoch:  7 | train loss: 0.0366\n",
      "Epoch:  7 | train loss: 0.0331\n",
      "Epoch:  7 | train loss: 0.0320\n",
      "Epoch:  7 | train loss: 0.0332\n",
      "Epoch:  7 | train loss: 0.0332\n",
      "Epoch:  7 | train loss: 0.0343\n",
      "Epoch:  7 | train loss: 0.0362\n",
      "Epoch:  7 | train loss: 0.0319\n",
      "Epoch:  8 | train loss: 0.0367\n",
      "Epoch:  8 | train loss: 0.0356\n",
      "Epoch:  8 | train loss: 0.0362\n",
      "Epoch:  8 | train loss: 0.0351\n",
      "Epoch:  8 | train loss: 0.0346\n",
      "Epoch:  8 | train loss: 0.0334\n",
      "Epoch:  8 | train loss: 0.0327\n",
      "Epoch:  8 | train loss: 0.0347\n",
      "Epoch:  8 | train loss: 0.0342\n",
      "Epoch:  8 | train loss: 0.0378\n",
      "Epoch:  9 | train loss: 0.0309\n",
      "Epoch:  9 | train loss: 0.0354\n",
      "Epoch:  9 | train loss: 0.0325\n",
      "Epoch:  9 | train loss: 0.0322\n",
      "Epoch:  9 | train loss: 0.0312\n",
      "Epoch:  9 | train loss: 0.0386\n",
      "Epoch:  9 | train loss: 0.0342\n",
      "Epoch:  9 | train loss: 0.0303\n",
      "Epoch:  9 | train loss: 0.0334\n",
      "Epoch:  9 | train loss: 0.0329\n"
     ]
    }
   ],
   "source": [
    "autoencoder = Autoencoder()\n",
    "print(autoencoder)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=LR)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "print(x.shape)\n",
    "\n",
    "#training 过程\n",
    "for epoch in range(EPOCH):\n",
    "    for step,(x,y) in enumerate(train_loader):#(x, y) 是当前 mini-batch 的数据\n",
    "        b_x = x.view(-1,28*28)\n",
    "        b_y = x.view(-1,28*28)\n",
    "        \n",
    "        encoded , decoded = autoencoder(b_x)\n",
    "        \n",
    "        loss = loss_func(decoded, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 100 ==0:\n",
    "            print('Epoch: ', epoch, '| train loss: %.4f' % loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6e1cf2",
   "metadata": {},
   "source": [
    "x.view(-1,28*28)中-1表示自动推导该维度的大小：  \n",
    "总元素数量保持不变，比如(64, 1, 28, 28)，总元素数量为64×1×28×28=50176，view(-1, 784)，则第一维 -1 会被自动计算为 64（因为50176÷784=64）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420f4aa6",
   "metadata": {},
   "source": [
    "Autoencoder 的目标是重构输入数据 x，而不是预测标签 y,所以有b_y = x.view(-1,28*28)，我们要的是原图像bx与的coded之后的x进行loss函数运算，而不是像分类问题一样需要分辨出这个数字是多少（需要标签y），而原图像就是x.view(-1,28*28)  \n",
    "也就是其中一个x.view(-1,28*28)作为输入进入了神经网络，另一个留下来进入y中，作为loss函数的计算标准"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
